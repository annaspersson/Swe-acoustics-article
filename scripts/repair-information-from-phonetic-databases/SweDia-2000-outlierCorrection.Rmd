---
title: "Outlier detection and removal in SweDia 2000 phonetic vowel database, reference talkers only"
output: html_document
date: "2023-11-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
geometric.mean = psych::geometric.mean

library(tidyverse)  # data wrangling and plotting
library(plotly)     # for interactive HTML plots
library(magrittr)
library(dplyr)
library(mvtnorm)    # for outlier identification
```

```{r}
source("../../output/papers/constants_functions.R")
```

# Overview
This document identifies, corrects and removes outliers in SweDia (2000) phonetic vowel database, the 8 young reference talkers only.

```{r load-data}
# Load the native talker data
d.vowels.swedia <- read.csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/raw-formant-data/vowel_formants_swedia.txt', sep = "\t", fileEncoding = "UTF-16BE") %>%
  mutate(
    Trial = as.numeric(gsub("^.*\\_([0-9]+)$", "\\1", Token)),
    F0.mean = ifelse(F0.mean == "--undefined--", NA, as.numeric(F0.mean)),
    Vowel = factor(
      plyr::mapvalues(
        Vowel,
        levels.vowel.SweFA,
        levels.vowel.IPA.swe),
      levels = levels.vowel.IPA.swe)) %>%
  rename(
    Talker = Filename,
    Duration = "Duration..s.",
    F0 = F0.mean) %>%
  # obtain SR %>%
  group_by(Talker) %>%
  mutate(F0_gm = geometric.mean(F0)) %>%
  ungroup() %>%
  mutate(SR = F0_to_SR(F0_gm)) %>%
  # create unique identifier for each vowel token
  group_by(Talker, Vowel) %>%
  mutate(Token = factor(as.numeric(as.factor(Trial))),
         Quantity = case_when(Vowel %in% levels.vowel.IPA.swe.long ~ "long",
                              Vowel %in% levels.vowel.IPA.swe.short ~"short"))

# Load male native vowel data
d.vowels.swedia.male <- read.csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/raw-formant-data/vowel_formants_swedia_male.txt', sep = "\t", fileEncoding = "UTF-16BE") %>%
  mutate(
    Trial = as.numeric(gsub("^.*\\_([0-9]+)$", "\\1", Token)),
    F0.mean = ifelse(F0.mean == "--undefined--", NA, as.numeric(F0.mean)),
    Vowel = factor(
      plyr::mapvalues(
        Vowel,
        levels.vowel.SweFA,
        levels.vowel.IPA.swe),
      levels = levels.vowel.IPA.swe)) %>%
  rename(
    Talker = Filename,
    Duration = "Duration..s.",
    F0 = F0.mean) %>%
  # obtain SR %>%
  group_by(Talker) %>%
  mutate(F0_gm = geometric.mean(F0)) %>%
  ungroup() %>%
  mutate(SR = F0_to_SR(F0_gm)) %>%
  # create unique identifier for each vowel token
  group_by(Talker, Vowel) %>%
  mutate(Token = factor(as.numeric(as.factor(Trial))),
         Quantity = case_when(Vowel %in% levels.vowel.IPA.swe.long ~ "long",
                              Vowel %in% levels.vowel.IPA.swe.short ~"short"))
```

```{r}
d.vowels.swedia %<>%
  # focus on F1-F2
  select(
    Talker, Vowel, Word, Token, Trial, F0_gm, F0, Duration, SR, Quantity,
    starts_with("F1"), starts_with("F2"), starts_with("F3")) %>%
  # have the 3 measures for each formant be in different rows, rather than columns
  pivot_longer(
    cols = c(
      starts_with("F1"),
      starts_with("F2"),
      starts_with("F3")),
    names_to = c("Formant", "Location"),
    names_pattern = "(F.)\\_(.[0-9]*)") %>%
  pivot_wider(
    names_from = "Formant",
    values_from = "value"
  ) %>%
  mutate(
    Database = "SweDia-2000",
    Gender = "female")

d.vowels.swedia.male %<>%
  # focus on F1-F2
  select(
    Talker, Vowel, Word, Token, Trial, F0_gm, F0, Duration, SR, Quantity,
    starts_with("F1"), starts_with("F2"), starts_with("F3")) %>%
  # have the 3 measures for each formant be in different rows, rather than columns
  pivot_longer(
    cols = c(
      starts_with("F1"),
      starts_with("F2"),
      starts_with("F3")),
    names_to = c("Formant", "Location"),
    names_pattern = "(F.)\\_(.[0-9]*)") %>%
  pivot_wider(
    names_from = "Formant",
    values_from = "value"
  ) %>%
  mutate(
    Database = "SweDia-2000",
    Gender = "male")

d.vowels.swedia %<>% rbind(d.vowels.swedia.male) %>%
  mutate(
    Age = case_when(Talker == "ref_ym_1" ~ 25,
                    Talker == "ref_ym_2" ~ 27,
                    Talker == "ref_ym_3" ~ NA,
                    Talker == "ref_ym_4" ~ 24,
                    Talker == "ref_yw_1" ~ 35,
                    Talker == "ref_yw_2" ~ 22,
                    Talker == "ref_yw_3" ~ NA,
                    Talker == "ref_yw_4" ~ NA))

d.vowels.swedia %>% 
# Plot the long/short vowels separately
    #filter(Quantity == "long") %>%
  group_by(Talker, Vowel, Token, Word, Quantity, Gender) %>%
  summarise(across(c(F1, F2, F3), ~ geometric.mean(.x))) %>%
  ggplot(
    aes(
      x = F2, 
      y = F1,
      color = Vowel,
      shape = Quantity, label = Token)) +
  scale_colour_manual(name = "Vowel",values = colors.vowel.swe) +
  geom_point(alpha = .5) + 
  scale_x_reverse() +
  scale_y_reverse() +
  scale_alpha_discrete("Outlier") +
  facet_wrap(Talker~ Gender)
```

```{r}
d.vowels.swedia %>% 
  # Get the geometric mean across all five time points for the five cues
  group_by(Talker, Vowel, Token, Quantity, Gender) %>%
  summarise(across(c(F0, F1, F2, F3, Duration), ~ geometric.mean(.x))) %>%
  ungroup() %>%
  ggplot(
    aes(F0)) +
  geom_density(
    mapping = aes(fill = Vowel, linetype = Gender), 
    alpha = .3, position = "identity") +
  facet_wrap(~Quantity, scales = "free")
```
# Identify missing F0

```{r}
# write.csv(
#   d.vowels.swedia %>%
#     # Mutate back to arpabet for csv readability
#     mutate(Vowel = factor(
#       plyr::mapvalues(
#         Vowel,
#         levels.vowel.IPA.swe,
#         levels.vowel.SweFA),
#       levels = levels.vowel.SweFA)) %>%
#     #rename(f0gm = F0_gm, f0m = F0.mean) %>%
#     group_by(Talker, Vowel) %>%
#     mutate(
#       F0_half = ifelse(F0 < (F0_gm / 2), TRUE, FALSE),
#       F0_double = ifelse(F0 > (F0_gm * 2), TRUE, FALSE)) %>%
#     filter(F0_half == TRUE | F0_double == TRUE | is.na(F0)) %>%
#     select(Talker, Vowel, Token, Trial, Location, Quantity, F1, F2, F0),
#   file = "../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_F0_to_repair.csv",
#   row.names = FALSE, quote = FALSE)

#Read in file with manually extracted F0s
d.vowels.swedia %<>%
  # add the corrected F0s
  left_join(
    read_csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_F0_repaired.csv') %>%
      select(Talker, Vowel, Token, Trial, Location, Quantity, F0) %>%
      mutate(
        Location = gsub("\\_", "", Location),
        Vowel = factor(
          plyr::mapvalues(
            Vowel,
            levels.vowel.SweFA,
            levels.vowel.IPA.swe),
          levels = levels.vowel.IPA.swe)) %>%
      mutate_at("Token", factor),
    by = c("Talker", "Vowel", "Token", "Trial", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y, .y), use that value; otherwise use the
  # automatically-extracted value (.x, .x).
  mutate(
    F0 = ifelse(!is.na(F0.y), F0.y, F0.x)) %>%
  select(-c(F0.x, F0.y))
```

```{r}
d.vowels.swedia %>% 
  # Get the geometric mean across all five time points for the five cues
  group_by(Talker, Vowel, Token, Quantity, Gender) %>%
  summarise(across(c(F0, F1, F2, F3, Duration), ~ geometric.mean(.x))) %>%
  ungroup() %>%
  ggplot(
    aes(F0)) +
  geom_density(
    mapping = aes(fill = Vowel, linetype = Gender), 
    alpha = .3, position = "identity") +
  facet_wrap(~Quantity)
```

# Correct f1-f3

```{r}
#Write a csvfile with eye-balled outliers
# write.csv(
#   d.vowels.swedia %>%
#     # Mutate back to arpabet for csv readability
#     mutate(Vowel = factor(
#       plyr::mapvalues(
#         Vowel,
#         levels.vowel.IPA.swe,
#         levels.vowel.SweFA),
#       levels = levels.vowel.SweFA)) %>%
#     select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3),
#   file = "../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_FFs_to_repair.csv",
#   row.names = FALSE, quote = FALSE)

#Read in file with manually corrected FFs
d.vowels.swedia %<>%
  # add the corrected FFs
  left_join(
    read_csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_FFs_repaired.csv') %>%
      select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3) %>%
      mutate(
        Location = gsub("\\_", "", Location),
        Vowel = factor(
          plyr::mapvalues(
            Vowel,
            levels.vowel.SweFA,
            levels.vowel.IPA.swe),
          levels = levels.vowel.IPA.swe)) %>%
      mutate_at("Token", factor),
    by = c("Talker", "Vowel", "Token", "Trial", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y, .y), use that value; otherwise use the
  # automatically-extracted value (.x, .x).
  mutate(
    F0 = ifelse(!is.na(F0.y), F0.y, F0.x),
    F1 = ifelse(!is.na(F1.y), F1.y, F1.x),
    F2 = ifelse(!is.na(F2.y), F2.y, F2.x),
    F3 = ifelse(!is.na(F3.y), F3.y, F3.x)) %>%
  select(-c(F0.x, F0.y, F1.x, F1.y, F2.x, F2.y, F3.x, F3.y))

d.vowels.swedia %>%
  group_by(Talker, Vowel, Token, Word, Quantity, Gender) %>%
  summarise(across(c(F1, F2, F3), ~ geometric.mean(.x))) %>%
  ggplot(
    aes(
      x = F2, 
      y = F1,
      color = Vowel,
      shape = Quantity, label = Token)) +
  scale_colour_manual(name = "Vowel",values = colors.vowel.swe) +
  geom_point(alpha = .5) + 
  scale_x_reverse() +
  scale_y_reverse() +
  scale_alpha_discrete("Outlier") +
  facet_grid(~ Gender)
```
```{r set-outlier-cutoff, include=F}
# What proportion of the most extreme values should be considered outliers? 
# (if set to e.g., .05 that means that points with cumulative densities below
# .025 or above .975 are considered outliers)
outlier_probability_cutoff = .01
```

```{r}
# identify outliers
d.swedia.outliers.univariate <- d.vowels.swedia %>%
  filter(!is.na(F0)) %>%
  obtain_densities_univariates() %>%
  select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3, Duration, starts_with("cumulative"))

d.swedia.outliers.multivariate <- d.vowels.swedia %>%
  filter(!is.na(F0)) %>%
  obtain_densities_allCues() %>%
  select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3, Duration, starts_with("cumulative"))

d.swedia.outliers.multivariate %<>%
  filter(!between(cumulative_probability_allCues, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
  rename(cumulative_probability = cumulative_probability_allCues) %>%
  mutate(outlier_source = "cues_multivariate")

d.vowels.swedia.repair <- rbind(
  #First get the F0 outliers
      d.swedia.outliers.univariate %>%
        select(-c(cumulative_probability_F1, cumulative_probability_F2, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F0, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F0) %>%
        mutate(outlier_source = "F0_univariate"),
      #Then get the F1 outliers
      d.swedia.outliers.univariate %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F2, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F1, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F1) %>%
        mutate(outlier_source = "F1_univariate"),
        #Then get the F2 outliers
      d.swedia.outliers.univariate %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F1, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F2, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F2) %>%
        mutate(outlier_source = "F2_univariate"),
        #Then get the F3 outliers
      d.swedia.outliers.univariate %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F1, cumulative_probability_F2, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F3, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F3) %>%
        mutate(outlier_source = "F3_univariate"),
        #Then get the Duration outliers
      d.swedia.outliers.univariate %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F1, cumulative_probability_F2, cumulative_probability_F3)) %>%
        filter(!between(cumulative_probability_Duration, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_Duration) %>%
        mutate(outlier_source = "Duration_univariate")) %>%
  left_join(
    d.swedia.outliers.multivariate,
    by = c("Talker", "Vowel", "Token", "Trial", "Location", "Quantity", "F0", "F1", "F2", "F3", "Duration")) %>%
  mutate(
    cumulative_probability = ifelse(is.na(cumulative_probability.x), cumulative_probability.y, cumulative_probability.x),
    outlier_source = ifelse(is.na(outlier_source.x), outlier_source.y, outlier_source.x)) %>%
  select(-c(cumulative_probability.x, outlier_source.x, cumulative_probability.y, outlier_source.y))

# Write a csvfile with outliers to repair with all cues BUT PRIOR TO WRITING A REPAIR FILE, CHECK WHETHER THE ALREADY REPAIRED DATA IS IN THERE (see above on f0 correction).
d.vowels.swedia.repair %<>%
  anti_join(read_csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_F0_repaired.csv') %>%
              select(Talker, Vowel, Token, Trial, Location, F0, Quantity) %>%
              mutate(
                Location = gsub("\\_", "", Location),
                Vowel = factor(
                  plyr::mapvalues(
                    Vowel,
                    levels.vowel.SweFA,
                    levels.vowel.IPA.swe),
                  levels = levels.vowel.IPA.swe)) %>%
              mutate_at("Token", factor),
            by = c("Talker", "Vowel", "Token", "Trial", "Location", "Quantity"))
    
# write.csv(
#   d.vowels.swedia.repair %>%
#     # Mutate back to arpabet for csv readability
#     mutate(Vowel = factor(
#       plyr::mapvalues(
#         Vowel,
#         levels.vowel.IPA.swe,
#         levels.vowel.SweFA),
#       levels = levels.vowel.SweFA)) %>%
#     select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3, outlier_source),
#   file = "../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_allCuesvowels_to_repair.csv",
#   row.names = FALSE, quote = FALSE)
```

```{r}
# Read in csv-file with manually repaired univariate values for F0, F1, F2 and F3 and join it to vowel data. Do separate read-ins for each corrected cue value as the rows otherwise duplicate
d.vowels.swedia.repaired <- 
  read_csv('../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_allCuesvowels_repaired.csv') %>%
  select(Talker, Vowel, Trial, Token, Location, F0, F1, F2, F3, Quantity, outlier_source) %>%
  mutate(
    Location = gsub("\\_", "", Location),
    Vowel = factor(
      plyr::mapvalues(
        Vowel,
        levels.vowel.SweFA,
        levels.vowel.IPA.swe),
      levels = levels.vowel.IPA.swe)) %>%
  mutate_at("Token", factor)

d.vowels.swedia %<>%
  select(Talker, Age, Gender, Vowel, Word, Token, Trial, Location, F1, F2, F3, F0_gm, F0, Duration, SR, Quantity) %>%
  # add the corrected values, but in a loop as the values otherwise duplicate
  left_join(
    d.vowels.swedia.repaired %>%
      filter(outlier_source == "F0_univariate") %>%
      select(-c(F1, F2, F3, outlier_source)),
      by = c("Talker", "Vowel", "Trial", "Token", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y), use that value; otherwise use the
  # automatically-extracted value (.x).
  mutate(
    F0 = ifelse(!is.na(F0.y), F0.y, F0.x)) %>%
  select(-c(F0.x, F0.y)) %>%
  left_join(
    d.vowels.swedia.repaired %>%
      filter(outlier_source == "F1_univariate") %>%
      select(-c(F0, F2, F3, outlier_source)),
    by = c("Talker", "Vowel", "Trial", "Token", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y), use that value; otherwise use the
  # automatically-extracted value (.x).
  mutate(
    F1 = ifelse(!is.na(F1.y), F1.y, F1.x)) %>%
  select(-c(F1.x, F1.y)) %>%
  left_join(
    d.vowels.swedia.repaired %>%
      filter(outlier_source == "F2_univariate") %>%
      select(-c(F0, F1, F3, outlier_source)),
      by = c("Talker", "Vowel", "Trial", "Token", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y), use that value; otherwise use the
  # automatically-extracted value (.x).
  mutate(
    F2 = ifelse(!is.na(F2.y), F2.y, F2.x)) %>%
  select(-c(F2.x, F2.y)) %>%
  left_join(
    d.vowels.swedia.repaired %>%
      filter(outlier_source == "F3_univariate") %>%
      select(-c(F0, F1, F2, outlier_source)),
    by = c("Talker", "Vowel", "Trial", "Token", "Location", "Quantity")) %>%
  # whenever there is a corrected value (.y), use that value; otherwise use the
  # automatically-extracted value (.x).
  mutate(
    F3 = ifelse(!is.na(F3.y), F3.y, F3.x)) %>%
  select(-c(F3.x, F3.y)) %>%
  select(Talker, Age, Gender, Vowel,  Word, Token, Trial, Location, F0_gm, F0, Duration, SR, F1, F2, F3, Quantity)

d.vowels.swedia %>%
  group_by(Talker, Vowel, Token, Word, Quantity, Gender) %>%
  summarise(across(c(F1, F2, F3), ~ geometric.mean(.x))) %>%
  ggplot(
    aes(
      x = F2, 
      y = F1,
      color = Vowel,
      shape = Gender, label = Token)) +
  scale_colour_manual(name = "Vowel",values = colors.vowel.swe) +
  geom_point(alpha = .5) + 
  #scale_shape_manual(values = c(1:8)) +
  scale_x_reverse() +
  scale_y_reverse() +
  facet_grid(~ Quantity)
```

```{r}
# There still seems to be outliers in the data. Set the cut-off to .5 instead
outlier_probability_cutoff = .05
  
d.swedia.outliers.univariate.round2 <- d.vowels.swedia %>%
  #filter(!is.na(F0)) %>%
  obtain_densities_univariates() %>%
  select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3, Duration, starts_with("cumulative"))

d.vowels.swedia.repair.round2 <- rbind(
  #First get the F0 outliers
      d.swedia.outliers.univariate.round2 %>%
        select(-c(cumulative_probability_F1, cumulative_probability_F2, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F0, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F0) %>%
        mutate(outlier_source = "F0_univariate"),
      #Then get the F1 outliers
      d.swedia.outliers.univariate.round2 %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F2, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F1, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F1) %>%
        mutate(outlier_source = "F1_univariate"),
        #Then get the F2 outliers
      d.swedia.outliers.univariate.round2 %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F1, cumulative_probability_F3, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F2, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F2) %>%
        mutate(outlier_source = "F2_univariate"),
        #Then get the F3 outliers
      d.swedia.outliers.univariate.round2 %>%
        select(-c(cumulative_probability_F0, cumulative_probability_F1, cumulative_probability_F2, cumulative_probability_Duration)) %>%
        filter(!between(cumulative_probability_F3, outlier_probability_cutoff, 1 - outlier_probability_cutoff)) %>%
        rename(cumulative_probability = cumulative_probability_F3) %>%
        mutate(outlier_source = "F3_univariate")) %>%
  arrange(Talker, Vowel, Token)

# write.csv(
#   d.vowels.swedia.repair.round2 %>%
#     # Mutate back to arpabet for csv readability
#     mutate(Vowel = factor(
#       plyr::mapvalues(
#         Vowel,
#         levels.vowel.IPA.swe,
#         levels.vowel.SweFA),
#       levels = levels.vowel.SweFA)) %>%
#     select(Talker, Vowel, Token, Trial, Location, Quantity, F0, F1, F2, F3, outlier_source),
#   file = "../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_allCuesvowels_to_repair_round2.csv",
#   row.names = FALSE, quote = FALSE)
```
```{r}
# Write csv-file with the manually corrected vowel data, but without removed outliers.
write.csv(
  d.vowels.swedia %>%
    # remove average F0 gm of each talker
    select(-F0_gm) %>%
    # Variable renaming
    rename(category = Vowel) %>%
    relocate(F0, .before = F1),
  file = "../../data/phonetic vowel statistics/Swedish/Published databases/SweDia2000/outlier-corrected-vowel-data/SweDia2000_vowels_wDistrOutliers.csv",
  row.names = FALSE, quote = FALSE)
```
